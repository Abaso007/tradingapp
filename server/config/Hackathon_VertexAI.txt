Okay, on the backend side, the machine learning part, the problem statement that we had was that we were getting certain news from different resources. And based on those news, we had to recommend to users whether to buy the stock or to sell the stock. So our first approach for that was prompt engineering. In this, we used a structured query, and we specified the stock that we wanted to analyze. And after that, we gave the model a few input and output examples to help it predict the right output. So let's suppose if I run this query, and I get a certain output between negative one and plus one, which signifies if it's negative, it means that a user should sell the stock. If it's positive, then you should buy the stock. So this is the first approach. This was integrated in our solution, and it performed comparatively better as opposed to using unstructured query. After that, because we wanted to train our models on a lot of data, we collected data. For example, this is the Apple stock data going back to 1981. So we collected all the data that we could get on different stocks, and then we mined relevant news articles related to those. And in the EDA process, we were able to correlate those news articles with the stock prices and how they changed. And in the end, we got a table in which we had margin gains of the day for that particular stock and all the news related to that stock. And also the total volume of trades that were made on the specific day. So then we use this data to fine tune our large language model. This has not yet been completed, but we have built a structure for it, and we are having some quota issues. That's why we haven't yet fully, this is not fully functional. But in the future, we plan to fine tune the large language model on this data. And we are hoping to get even better results than we get with the structured query, structured prompt engineering. Moving on, in a production case, I think the system would be implemented as a streaming platform. Like we'll be continuously streaming in news from different resources about different stocks. And based on those news and performing sentiment analysis on those news, we'll be continuously updating the value of each stock and whether if the stock is undervalued or if it's overvalued. So in a real world system, we'll have a large language model that would be giving us predictions for multiple stocks, and it would be continuously be feeding on data from different data streams from the news outlets. So I think this would be a very good, this would be a very much refined approach as opposed to what we present right here. But right now, this is how much progress we made, and I'm hopeful going forward, we'll be able to perform even better.